# -*- coding: utf-8 -*-
"""Cube Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MY1uH_NuH8oaEvPbgMErlX8xHsbIPllf

**Install the libraries**
"""

!pip install "numpy<2.0"

!pip install opencv-contrib-python==4.7.0.72

"""**All necessary libraries**"""

import cv2
import numpy as np
import matplotlib.pyplot as plt

from IPython.display import display, Javascript, Image
from google.colab.output import eval_js
from PIL import Image
import base64
from io import BytesIO

"""**Webcam Image Input**"""

def capture_cube_face(outer_ratio=0.75, inner_ratio=0.5, save_name="cube_face.jpg"):
    """
    Opens webcam, draws two center squares (outer + inner),
    waits for user to click "Capture",
    returns cropped outer square region resized to 720√ó720.
    """

    js_code = f'''
    async function captureWithDualSquares() {{
      const video = document.createElement('video');
      video.style.position = "relative";
      video.style.display = "block";
      document.body.appendChild(video);

      const stream = await navigator.mediaDevices.getUserMedia({{video: true}});
      video.srcObject = stream;
      await video.play();

      const canvas = document.createElement('canvas');
      document.body.appendChild(canvas);
      const ctx = canvas.getContext('2d');

      function drawLoop() {{
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        ctx.drawImage(video, 0, 0);

        const w = canvas.width;
        const h = canvas.height;
        const minDim = Math.min(w, h);

        const outerSize = Math.floor(minDim * {outer_ratio});
        const outerX = Math.floor((w - outerSize) / 2);
        const outerY = Math.floor((h - outerSize) / 2);

        const innerSize = Math.floor(minDim * {inner_ratio});
        const innerX = Math.floor((w - innerSize) / 2);
        const innerY = Math.floor((h - innerSize) / 2);

        ctx.lineWidth = 4;
        ctx.strokeStyle = "lime";
        ctx.strokeRect(outerX, outerY, outerSize, outerSize);

        ctx.lineWidth = 3;
        ctx.strokeStyle = "yellow";
        ctx.strokeRect(innerX, innerY, innerSize, innerSize);

        requestAnimationFrame(drawLoop);
      }}
      requestAnimationFrame(drawLoop);

      await new Promise((resolve) => {{
        const btn = document.createElement('button');
        btn.textContent = "üì∑ Capture Cube Face";
        btn.style = "font-size:20px; margin-top:10px;";
        document.body.appendChild(btn);
        btn.onclick = resolve;
      }});

      const finalCanvas = document.createElement('canvas');
      finalCanvas.width = video.videoWidth;
      finalCanvas.height = video.videoHeight;
      finalCanvas.getContext('2d').drawImage(video, 0, 0);
      const dataUrl = finalCanvas.toDataURL('image/jpeg', 0.95);

      stream.getVideoTracks()[0].stop();
      return dataUrl;
    }}
    '''

    display(Javascript(js_code))
    data = eval_js("captureWithDualSquares()")

    # Convert base64 ‚Üí numpy image
    img_bytes = base64.b64decode(data.split(',')[1])
    img = Image.open(BytesIO(img_bytes))
    img_np = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)

    # Crop the outer square
    H, W, _ = img_np.shape
    min_dim = min(H, W)
    outer_size = int(min_dim * outer_ratio)

    outer_x = (W - outer_size) // 2
    outer_y = (H - outer_size) // 2
    outer_x2 = outer_x + outer_size
    outer_y2 = outer_y + outer_size

    cropped = img_np[outer_y:outer_y2, outer_x:outer_x2]

    # ‚≠ê Resize to exactly 720√ó720 for SIFT
    cropped_720 = cv2.resize(cropped, (720, 720), interpolation=cv2.INTER_CUBIC)

    # Save output
    cv2.imwrite(save_name, cropped_720)

    return cropped_720

# Capture with dual squares
cropped_face = capture_cube_face(outer_ratio=0.5, inner_ratio=0.3)

# Show the cropped result
plt.figure(figsize=(5,5))
plt.imshow(cv2.cvtColor(cropped_face, cv2.COLOR_BGR2RGB))
plt.title("Cropped Cube Face (Outer Square)")
plt.axis("off")
plt.show()

print("Cropped face shape:", cropped_face.shape)

from google.colab import files
files.download("cube_face.jpg")

"""**Face Transformation**"""

def extract_cube_pipeline_step3(
    cropped_face,
    outer_ratio=0.75,
    inner_ratio=0.50,
    alpha=2,
    beta=30,
    gaussian_kernel=(5, 5),
    unsharp_weight=2,
    kernel_size=21,
    roi_gaussian_scale=1/3
):
    original = cropped_face.copy()
    H, W = original.shape[:2]

    # 1. PREPROCESSING
    adj = cv2.convertScaleAbs(original, alpha=alpha, beta=beta)
    blur = cv2.GaussianBlur(adj, gaussian_kernel, 5)
    sharp = cv2.addWeighted(adj, unsharp_weight, blur, -(unsharp_weight - 1), 0)
    preprocessed_color = sharp.copy()
    pre_gray = cv2.cvtColor(preprocessed_color, cv2.COLOR_BGR2GRAY)

    # 2. ADAPTIVE THRESHOLD + CLOSING
    th = cv2.adaptiveThreshold(
        pre_gray, 255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY_INV,
        21, 5
    )
    th_closed = cv2.morphologyEx(th, cv2.MORPH_CLOSE, np.ones((5,5), np.uint8))

    # 3. ROIs
    outer_size = float(W)
    inner_size = outer_size * (inner_ratio / outer_ratio)
    ring = int((outer_size - inner_size) / 2)

    TL_roi = (0, ring, 0, ring)
    TR_roi = (W-ring, W, 0, ring)
    BR_roi = (W-ring, W, H-ring, H)
    BL_roi = (0, ring, H-ring, H)

    # 3B. BUILD TEMPLATE KERNELS
    k = kernel_size
    K = np.zeros((k, k), dtype=np.float32)
    center = k // 2

    for i in range(k):
        for j in range(k):
            dist = np.sqrt((i-center)**2 + (j-center)**2)
            K[i,j] = max(0, 1 - dist / (center * 1.2))

    TL_kernel = K.copy()
    TL_kernel[k//2:, :] = 0
    TL_kernel[:, k//2:] = 0

    TR_kernel = K.copy()
    TR_kernel[k//2:, :] = 0
    TR_kernel[:, :k//2] = 0

    BR_kernel = K.copy()
    BR_kernel[:k//2, :] = 0
    BR_kernel[:, :k//2] = 0

    BL_kernel = K.copy()
    BL_kernel[:k//2, :] = 0
    BL_kernel[:, k//2:] = 0

    TL_kernel /= np.sum(TL_kernel)
    TR_kernel /= np.sum(TR_kernel)
    BR_kernel /= np.sum(BR_kernel)
    BL_kernel /= np.sum(BL_kernel)

    # 3C. DETECT CORNERS
    def detect_corner_with_kernel(th_img, roi, kernel):
        x1, x2, y1, y2 = roi
        patch = th_img[y1:y2, x1:x2].astype(np.float32)
        h, w = patch.shape

        if h < kernel.shape[0] or w < kernel.shape[1]:
            return None

        response = cv2.filter2D(patch, -1, kernel)

        sx = np.linspace(-1, 1, w)
        sy = np.linspace(-1, 1, h)
        X, Y = np.meshgrid(sx, sy)

        sigma = roi_gaussian_scale
        region_weight = np.exp(-(X*X + Y*Y) / (2 * sigma*sigma))

        weighted_response = response * region_weight

        ry, rx = np.unravel_index(np.argmax(weighted_response), weighted_response.shape)
        return np.array([rx + x1, ry + y1], dtype=np.float32)

    tl = detect_corner_with_kernel(th_closed, TL_roi, TL_kernel)
    tr = detect_corner_with_kernel(th_closed, TR_roi, TR_kernel)
    br = detect_corner_with_kernel(th_closed, BR_roi, BR_kernel)
    bl = detect_corner_with_kernel(th_closed, BL_roi, BL_kernel)

    if any(v is None for v in [tl, tr, br, bl]):
        print("‚ùå Corner detection failed.")
        return original, preprocessed_color, th_closed, None, None

    corners = np.float32([tl, tr, br, bl])

    # Draw the corners
    th_vis = cv2.cvtColor(th_closed, cv2.COLOR_GRAY2BGR)
    for (x,y) in corners:
        cv2.circle(th_vis, (int(x), int(y)), 10, (0,0,255), -1)

    # RETURN
    return (
        original,
        preprocessed_color,
        th_closed,
        th_vis,
        corners   # ‚≠ê new return value
    )

# === TEST extract_cube_pipeline_step3 with ROI corner detection ===

outer_ratio = 0.75     # MUST match capture_cube_face()
inner_ratio = 0.50     # MUST match capture_cube_face()

orig, preproc, th_closed, th_corners, corners = extract_cube_pipeline_step3(
    cropped_face,
    outer_ratio=outer_ratio,
    inner_ratio=inner_ratio,
    alpha=2,
    beta=30,
    gaussian_kernel=(5,5),
    unsharp_weight=2,
    kernel_size=21,
    roi_gaussian_scale=1/3
)

# If corner detection failed
if th_corners is None or corners is None:
    print("‚ùå Corner detection failed ‚Äî no visualization available.")
else:
    print("Detected corner coordinates (TL, TR, BR, BL):")
    print(corners)

plt.figure(figsize=(10,10))

titles = [
    "Original",
    "Preprocessed (Contrast + Sharpen)",
    "Adaptive Threshold + Morph Closing",
    "Threshold with ROI-Based Corner Dots"
]

imgs = [orig, preproc, th_closed, th_corners]

for i in range(4):
    plt.subplot(2, 2, i+1)

    # grayscale or BGR handling
    if imgs[i] is None:
        plt.text(0.5, 0.5, "None", ha='center', va='center', fontsize=20)
        plt.axis("off")
        continue

    if len(imgs[i].shape) == 2:
        plt.imshow(imgs[i], cmap='gray')
    else:
        plt.imshow(cv2.cvtColor(imgs[i], cv2.COLOR_BGR2RGB))

    plt.title(titles[i])
    plt.axis("off")

plt.tight_layout()
plt.show()

def transform_cube_face(corners, img, warp_size=450):
    """
    Perform a perspective warp of the cube face based on 4 detected corners.

    Inputs:
      corners: numpy array of shape (4,2) in TL, TR, BR, BL order
      img:     preprocessed OR original image (BGR)
      warp_size: output cube face resolution (int)

    Returns:
      warped:  the 4-anchor perspective-corrected face (warp_size √ó warp_size)
    """

    if corners is None or img is None:
        print("‚ùå Missing input (corners or image)")
        return None

    # Ensure float32 format
    src_pts = corners.astype(np.float32)

    # Destination is a perfect square
    dst_pts = np.float32([
        [0, 0],
        [warp_size - 1, 0],
        [warp_size - 1, warp_size - 1],
        [0, warp_size - 1]
    ])

    # Compute perspective transform
    H = cv2.getPerspectiveTransform(src_pts, dst_pts)

    # Warp the image
    warped = cv2.warpPerspective(img, H, (warp_size, warp_size))

    return warped

# === TEST: Warp the cube face using detected corners ===

warp_size = 450

warped_face = transform_cube_face(corners, orig, warp_size=warp_size)

if warped_face is None:
    print("‚ùå Warp failed ‚Äî missing corners.")
else:
    print("Warp succeeded!")

plt.figure(figsize=(8,8))
plt.imshow(cv2.cvtColor(warped_face, cv2.COLOR_BGR2RGB))
plt.title("Warped Cube Face (Perspective Corrected)")
plt.axis("off")
plt.show()

"""**Image Processing**"""

import cv2
import numpy as np

def enhance_rubik_face(
    warped_face,
    gamma=2.0,              # brightness
    contrast=1.5,           # contrast
    color_boost=1.3,        # saturation boost
    blur_type="gaussian",   # "gaussian" or "median"
    blur_ksize=5            # odd number, e.g., 3,5,7
):
    """
    Returns 6 images:
      1. original input
      2. after brightness
      3. after brightness + contrast
      4. after brightness + contrast + color boost
      5. after blur (noise reduction)
      6. final output (same as stage 5)
    """

    # ---------------------------------------------------
    # 1. Original Input
    # ---------------------------------------------------
    img_input = warped_face.copy()

    # ---------------------------------------------------
    # 2. Brightness via Gamma Correction
    # ---------------------------------------------------
    table = np.array([
        ((i / 255.0) ** (1.0 / gamma)) * 255
        for i in range(256)
    ]).astype("uint8")

    img_brightness = cv2.LUT(img_input, table)

    # ---------------------------------------------------
    # 3. Contrast
    # ---------------------------------------------------
    img_f = img_brightness.astype(np.float32)
    img_bright_contrast = (img_f - 128) * contrast + 128
    img_bright_contrast = np.clip(img_bright_contrast, 0, 255).astype(np.uint8)

    # ---------------------------------------------------
    # 4. Color Boost (increase saturation)
    # ---------------------------------------------------
    hsv = cv2.cvtColor(img_bright_contrast, cv2.COLOR_BGR2HSV).astype(np.float32)
    H, S, V = cv2.split(hsv)

    S *= color_boost
    S = np.clip(S, 0, 255)

    hsv_boosted = cv2.merge([H, S, V]).astype(np.uint8)
    img_color_boost = cv2.cvtColor(hsv_boosted, cv2.COLOR_HSV2BGR)

    # ---------------------------------------------------
    # 5. Blur (Noise Reduction)
    # ---------------------------------------------------
    if blur_type == "gaussian":
        img_blur = cv2.GaussianBlur(img_color_boost, (blur_ksize, blur_ksize), 0)
    else:
        img_blur = cv2.medianBlur(img_color_boost, blur_ksize)

    # ---------------------------------------------------
    # 6. Final Output
    # ---------------------------------------------------
    final_img = img_blur.copy()

    return (
        img_input,
        img_brightness,
        img_bright_contrast,
        img_color_boost,
        img_blur,
        final_img
    )

gamma_value = 3
contrast_value = 2
color_boost_value = 1.1
gaussian_blur_kernel_size = 15

imgs = enhance_rubik_face(
    warped_face,
    gamma=gamma_value,
    contrast=contrast_value,
    color_boost=color_boost_value,
    blur_type="gaussian",
    blur_ksize=gaussian_blur_kernel_size
)

titles = [
    "1. Input Image",
    "2. After Brightness",
    "3. After Brightness + Contrast",
    "4. After Color Boost",
    "5. After Blur (Noise Reduction)",
    "6. Final Output"
]

plt.figure(figsize=(14,14))

for i in range(6):
    plt.subplot(3, 3, i+1)
    plt.imshow(cv2.cvtColor(imgs[i], cv2.COLOR_BGR2RGB))
    plt.title(titles[i])
    plt.axis("off")

plt.tight_layout()
plt.show()